# top200-rs Project Overview

I'm working on `top200-rs`, a Rust-based market data tracking system for the top 200 fashion and retail companies. Here are the key documents to help you understand the current state and context:

// General guidelines
Always use Markdown for documentation and README files
Maintain the existing structure of the README.md file

// README.md structure
Maintain the following structure in the README.md file:

  1. Title and Awesome badge
  2. Fork information and differences
  3. Short description
  4. "Why Use Rules in Windsurf?" section
     - Benefits of Global Rules
     - Benefits of Workspace Rules
  5. Content
     - Global Rules
     - Workspace Rules
  6. Directories
  7. How to Use section
  8. Contributing section
  9. License section

- Main Documentation: [README.md](README.md) - Core vision, implementation details, and setup instructions
- Data Collection: Daily automated collection of market cap data for fashion/retail companies
- Market Analysis: Support for US, EU, and combined market analysis
- Historical Tracking: End-of-year valuations and market cap history

# Financial Data Application Architecture

## Domain Model

```
Companies
  - ticker: String (primary key)
  - name: String
  - sector: String
  - market_cap: Decimal
  - currency: String
  - last_updated: DateTime

Currencies
  - code: String (primary key)
  - name: String
  - exchange_rate_usd: Decimal
  - last_updated: DateTime

HistoricalMarketCaps
  - id: UUID (primary key)
  - ticker: String (foreign key)
  - market_cap: Decimal
  - date: Date
```

## System Architecture

1. **Data Fetcher Service**
   - Rust service using reqwest for API calls
   - Scheduled jobs to fetch and normalize data
   - Stores in Postgres via sqlx

2. **API Service**
   - Rust/Axum REST API
   - Endpoints:
     - `/companies/top?limit=100`
     - `/companies/:ticker`
     - `/analysis/movers?period=month`

3. **PostgreSQL on GCP**
   - Cloud SQL instance
   - Optimized indexes for market cap sorting

## Implementation Plan

1. Create basic Rust project structure with cargo
2. Implement data fetcher:
   - API client for FinancialModelingPrep
   - Data transformation for Postgres
3. Set up database schema and migrations
4. Create API endpoints with proper error handling
5. Deploy to GCP (Cloud Run + Cloud SQL)
6. Implement time-series analysis for movers

The project uses modern Rust tooling with SQLx for database operations, and includes comprehensive CI/CD through GitHub Actions for reliable deployment and testing.
